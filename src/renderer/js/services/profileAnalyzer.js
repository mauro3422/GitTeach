/**
 * ProfileAnalyzer - Orchestrates specialized modules for user analysis (Facade).
 */
import { AIService } from './aiService.js';
import { CoordinatorAgent } from './coordinatorAgent.js';
import { AIWorkerPool } from './aiWorkerPool.js';
import { CodeScanner } from './codeScanner.js';
import { DeepCurator } from './deepCurator.js';
import { IntelligenceSynthesizer } from './intelligenceSynthesizer.js';
import { Logger } from '../utils/logger.js';
import { CacheRepository } from '../utils/cacheRepository.js';
import { ContextBuilder } from './analyzer/ContextBuilder.js';
import { FlowManager } from './analyzer/FlowManager.js';
import { ReactionEngine } from './analyzer/ReactionEngine.js';
import { memoryManager } from './memory/MemoryManager.js';

console.log("!!! PROFILE ANALYZER RELOADED - VERSION RESURRECTION !!!");

export class ProfileAnalyzer {
    constructor(debugLogger = null, options = {}) {
        this.results = FlowManager.getInitialResults();
        this.isAnalyzing = false;
        this.debugLogger = debugLogger;
        this.options = options;

        this.coordinator = new CoordinatorAgent();
        this.workerPool = new AIWorkerPool(3, this.coordinator, debugLogger);
        this.codeScanner = new CodeScanner(this.coordinator, this.workerPool);
        this.deepCurator = new DeepCurator();
        this.intelligenceSynthesizer = new IntelligenceSynthesizer(null, debugLogger);
    }

    async analyze(username, onStep = null) {
        if (this.isAnalyzing) return;
        this.isAnalyzing = true;

        let repos = []; // Initialize repos here

        try {
            const cachedIdentity = await CacheRepository.getTechnicalIdentity(username);
            const cachedFindings = await CacheRepository.getTechnicalFindings(username);
            const savedProfile = await this.intelligenceSynthesizer.loadFromDisk(username);

            AIService.setSessionContext(this.getFreshContext(username, cachedIdentity, savedProfile, cachedFindings));

            console.log(`[ProfileAnalyzer] ENV CHECK: window=${typeof window}, githubAPI=${typeof window !== 'undefined' ? !!window.githubAPI : 'N/A'}`);

            const githubAPI = this.options.githubAPI || (typeof window !== 'undefined' ? window.githubAPI : null);

            const [repos, audit] = await Promise.all([
                githubAPI ? githubAPI.listRepos() : Promise.resolve([]),
                this.runAuditorAgent(username)
            ]);

            // STREAMING ARCHITECTURE: Bridge Coordinator -> DeepCurator
            // MUST be set BEFORE scan() to catch cached repos that complete immediately
            this.coordinator.onRepoComplete = (repoName) => {
                this.deepCurator.processStreamingRepo(username, repoName, this.coordinator);
                if (onStep) onStep({ type: 'StreamingUpdate', message: `âš¡ Streaming Blueprint: ${repoName} (Final)` });
            };

            // PARTIAL STREAMING: Update every 3 files
            this.coordinator.onRepoBatchReady = (repoName) => {
                this.deepCurator.processStreamingRepo(username, repoName, this.coordinator, true); // true = partial
                if (onStep) onStep({ type: 'StreamingUpdate', message: `ðŸŒŠ Partial Update: ${repoName}` });
            };

            let codeInsights = [];
            let allFindings = [];
            if (typeof window !== 'undefined' && !window.AI_OFFLINE) {
                allFindings = await this.codeScanner.scan(username, repos, onStep);
                codeInsights = this.codeScanner.curateFindings(allFindings);
            }

            const langData = FlowManager.processLanguages(repos);
            let aiInsight = { summary: "IA Offline.", suggestions: [] };
            if (typeof window !== 'undefined' && !window.AI_OFFLINE) {
                aiInsight = await this.deepCurator.getAIInsights(username, langData, codeInsights, codeInsights.length > 0);
            }

            this.results = FlowManager.finalizeResults(username, repos, aiInsight, langData, codeInsights, this.coordinator);
            this.results.audit = audit;

            this.startWorkerProcessing(onStep, username);

            // UNIFIED QUEUE: Processing background files via CodeScanner (Low Priority)
            this.backgroundPromise = this.codeScanner.processBackgroundFiles(username, allFindings, (data) => {
                if (onStep) onStep(data);
            });

            this.fullIntelligencePromise = this._runFinalSynthesis(username, onStep);

            return this.results;
        } catch (error) {
            console.error("âŒ Analysis Error:", error);
            // Even if scanning fails, try to finalize with what we have
            const langData = FlowManager.processLanguages(repos || []);
            this.results = FlowManager.finalizeResults(username, repos || [], { summary: "Error parcial durante el escaneo." }, langData, [], this.coordinator);
            return this.results;
        } finally {
            this.isAnalyzing = false;
        }
    }

    async _runFinalSynthesis(username, onStep) {
        try {
            await Promise.all([this.backgroundPromise, this.aiWorkersPromise || Promise.resolve()]);

            // TRACER FIX: Ensure any background items added are actually processed
            // Since AIWorkerPool might have terminated early if queue was empty initially
            // We need to import AIService from module scope (it is imported at top)
            const { AIService } = await import('./aiService.js');

            console.log(`[ProfileAnalyzer] Check Queue: Total=${this.workerPool.totalQueued}, Active=${this.workerPool.isProcessing}`);

            if (this.workerPool.totalQueued > 0) {
                console.log(`[ProfileAnalyzer] FORCE RESTARTING WorkerPool for ${this.workerPool.totalQueued} pending items...`);
                await this.workerPool.processQueue(AIService);
            } else {
                console.log("[ProfileAnalyzer] Queue empty, no restart needed.");
            }

            // SAFETY NET: If WorkerPool failed to populate StreamingHandler, pull from Coordinator
            // This covers the case where workers died early or queue ingestion was silent
            const currentFindings = this.deepCurator.streamingHandler.getAccumulatedFindings();
            if (currentFindings.length === 0) {
                const coordinatorFindings = this.coordinator.getAllRichSummaries();
                if (coordinatorFindings.length > 0) {
                    console.warn(`[ProfileAnalyzer] âš ï¸ WORKER BYPASS: Manually resurrecting ${coordinatorFindings.length} findings from Coordinator.`);

                    const resurrected = coordinatorFindings.map(f => ({
                        repo: f.repo,
                        path: f.path,
                        file: f.path || 'unknown',
                        summary: f.params?.insight || f.summary || `Content analyzed (Coordinator Fallback)`,
                        workerId: 'fallback',
                        classification: f.classification || 'General',
                        uid: f.uid || Math.random().toString(36).substring(7),
                        file_meta: f.file_meta || {},
                        // Preserve metadata and params for thematic aggregators
                        metadata: f.metadata || (f.params?.metadata ? f.params.metadata : {}),
                        params: f.params || { metadata: f.metadata || {} }
                    }));

                    this.deepCurator.incorporateBatch(resurrected);
                }
            }

            // PERSISTENCE V3: Flush all repo memories before synthesis strategy
            await memoryManager.persistAll();

            Logger.reducer('Executing FINAL SYNTHESIS...');
            const curationResult = await this.deepCurator.runDeepCurator(username, this.coordinator);
            if (!curationResult || curationResult.error) {
                Logger.error('ANALYZER', `Synthesis failed: ${curationResult?.error || 'No result'}`);
                return null;
            }

            const oldIdentity = await CacheRepository.getTechnicalIdentity(username);
            // Sintetizar Identidad (Personalidad) a partir del ADN TÃ©cnico
            const { finalProfile, report, isSignificant } = await this.intelligenceSynthesizer.synthesizeProfile(oldIdentity, curationResult.dna);

            // Forensics: Attach performance metrics for Tracer
            finalProfile.performance = curationResult.performance;

            await CacheRepository.setTechnicalIdentity(username, finalProfile);
            // Log the traceability map for debugging, with a fallback for join
            Logger.debug('ANALYZER', `### TRACEABILITY MAP:\n${Array.isArray(curationResult.traceability_map) ? curationResult.traceability_map.join('\n') : ''}`);
            if (curationResult.traceability_map) {
                await CacheRepository.setTechnicalFindings(username, curationResult.traceability_map);
            }

            // Inyectar contexto: Identidad TÃ©cnica (Personalidad) + ADN (Trazabilidad) + Memoria (Hallazgos)
            AIService.setSessionContext(this.getFreshContext(username, finalProfile, this.intelligenceSynthesizer.technicalProfile, curationResult.traceability_map));

            if (isSignificant && report.milestone !== 'INITIAL_SYNTHESIS') {
                const reactiveMsg = `DNA_EVOLUTION_DETECTED: ${report.evolutionSnapshot || 'Nuevos rasgos detectados.'}`;
                ReactionEngine.trigger(username, reactiveMsg, 'system');
            }

            if (onStep) onStep({ type: 'DeepMemoryReady', message: isSignificant ? 'ðŸ§  Identidad Evolucionada!' : 'ðŸ§  Memoria sincronizada.', data: finalProfile });
            return finalProfile;
        } catch (error) {
            console.error("âŒ Final Synthesis Error:", error);
            Logger.error('ANALYZER', `Final synthesis failed: ${error.message}`);
            return null;
        }
    }

    async runAuditorAgent(username) {
        try {
            const { ToolRegistry } = await import('./toolRegistry.js');
            const auditor = ToolRegistry.getById('readability_auditor');
            return auditor ? await auditor.execute({}, username) : { score: 0 };
        } catch (e) { return { score: 0 }; }
    }

    async startWorkerProcessing(onStep, username) {
        // if (this.workerPool.totalQueued === 0) return; // REMOVED: Listener must attach regardless of initial state (Race Condition Fix)

        this.workerPool.onProgress = (data) => {
            if (onStep) onStep({ type: 'Progreso', percent: data.percent, message: `ðŸ¤– Worker ${data.workerId}: Processed` });
        };
        console.log("ProfileAnalyzer: Listener Attached (onBatchComplete)");
        // Listen for batch completion (Concurrent)
        // This receives the batch from AIWorkerPool -> WorkerHealthMonitor
        this.workerPool.onBatchComplete = async (batch) => {
            console.log(`ProfileAnalyzer: onBatchComplete RECV batch=${batch ? batch.length : 'null'}`);
            // EMERGENCY FIX: Reconstruct objects to ensure validity (Ghost Object Protocol)
            // We create FRESH objects to bypass any immutability or reference issues
            // EMERGENCY FIX: Reconstruct objects force-breaking references (Deep Clone)
            // We create FRESH objects to bypass any immutability or reference issues
            const fixedBatch = batch.map(f => {
                const safePath = f.path || f.file || 'unknown';
                const safeSummary = f.summary || (f.content ? `Analyzed content (${f.content.length} chars)` : "No Summary Available (Resurrected)");

                return {
                    repo: f.repo,
                    path: safePath,
                    file: safePath,
                    summary: safeSummary,
                    workerId: f.workerId || 999,
                    classification: f.classification || 'General',
                    uid: f.uid,
                    file_meta: f.file_meta || {},
                    metadata: f.metadata || {},
                    params: f.params || {}
                };
            });

            // Log first item to verify resurrection
            if (fixedBatch.length > 0) {
                console.log(`[ProfileAnalyzer] Resurrected Batch: Size=${fixedBatch.length}, Item0 Summary=${!!fixedBatch[0].summary}, Path=${fixedBatch[0].path}`);
                // console.log("DUMP:", JSON.stringify(fixedBatch[0]));
            }

            // CRITICAL: Pass to Curator FIRST to avoid any mutation by MemoryManager
            const stats = this.deepCurator.incorporateBatch(fixedBatch);

            // Persist to Graph Memory (Async)
            // Use for...of to ensure we await the async storeFinding
            for (const finding of fixedBatch) {
                const node = await memoryManager.storeFinding(finding);
                // Attach the UID to the finding for later curation linking
                finding.uid = node.uid;
            }

            const reflection = this.intelligenceSynthesizer.synthesizeBatch(stats);
            if (reflection.isSignificant) {
                Logger.success('ANALYZER', `ðŸ’¡ Intermediate Evolution: ${reflection.snapshot}`);
                if (onStep) onStep({ type: 'DeepMemoryReady', message: `ðŸ§  ${reflection.snapshot}`, data: null });

                ReactionEngine.trigger(username, reflection.snapshot, 'system');
            }

            // NOTIFY EXTERNAL LISTENERS (Tracer, UI, etc)
            if (this.onBatchComplete && typeof this.onBatchComplete === 'function') {
                await this.onBatchComplete(fixedBatch);
            }
        };

        this.aiWorkersPromise = this.workerPool.processQueue(AIService).catch(err => console.warn('[AI WORKERS] Error:', err));
    }

    getFreshContext(username, technicalIdentity, cognitiveProfile = null, curationEvidence = null) {
        return ContextBuilder.build(username, this.results, technicalIdentity, cognitiveProfile, curationEvidence, () => this.coordinator.getSummaryForChat());
    }
}
